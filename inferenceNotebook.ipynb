{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6e53eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/Extreme SSD/MLWork/DocAI/TestImage/Invoice38\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\"\"\"Convert files of a selected directory in jpg format\"\"\"\n",
    "import converter\n",
    "# !pip install easyocr\n",
    "import easyocr\n",
    "#download the model\n",
    "reader = easyocr.Reader(['en'], gpu = True)\n",
    "# show an image\n",
    "import PIL\n",
    "from PIL import ImageDraw\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import PIL\n",
    "from PIL import ImageDraw\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "# import xlrd\n",
    "import csv\n",
    "\n",
    "\n",
    "# import os\n",
    "# print(os.getcwd())\n",
    "# # path = '/Users/neerajyadav/Documents/pycv/PICK-pytorch/'\n",
    "# path = '/Volumes/Extreme SSD/MLWork/DocAI/PICK-pytorch'\n",
    "# os.chdir(path)\n",
    "# import argparse\n",
    "# import torch\n",
    "# from tqdm import tqdm\n",
    "# from pathlib import Path\n",
    "# from torch.utils.data.dataloader import DataLoader\n",
    "# from allennlp.data.dataset_readers.dataset_utils.span_utils import bio_tags_to_spans\n",
    "# from parse_config import ConfigParser\n",
    "# import model.pick as pick_arch_module\n",
    "# from data_utils.pick_dataset import PICKDataset\n",
    "# from data_utils.pick_dataset import BatchCollateFn\n",
    "# from utils.util import iob_index_to_str, text_index_to_str\n",
    "# import converter\n",
    "import shutil, os\n",
    "\n",
    "\n",
    "### convert image into transcript file \n",
    "\"\"\"Select jpg files and convert into transcript files\"\"\"\n",
    "filenames = glob.glob(\"/Volumes/Extreme SSD/MLWork/DocAI/TestImage/*.jpg\")\n",
    "filenamesj = glob.glob(\"/Volumes/Extreme SSD/MLWork/DocAI/TestImage/*.jpeg\")\n",
    "filenames = filenames + filenamesj\n",
    "filenames.sort()\n",
    "\n",
    "def draw_boxes(image, bounds, color='green', width=1):\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    for bound in bounds:\n",
    "        p0, p1, p2, p3 = bound[0]\n",
    "        draw.line([*p0, *p1, *p2, *p3, *p0], fill=color , width=width)\n",
    "        # if bound[1] == \"ToTAL\" or bound[1] ==\"TOTAL\" or bound[1]==\"TOTAL\" or bound[1] ==\"Total Payable;\" or bound[1] ==\"Total Payable:\" or bound[1] ==\"Total Payable:\" or bound[1]=='Total' or bound[1]=='TOTAL' or bound[1]==\"Totz' Ingi, 0f GST\" or bound[1]==\"Total Sales (Inclusive of GST)\" or bound[1]==\"Net Total (MYR)\":\n",
    "          # draw.line([*p0, *p1, *p2, *p3, *p0], fill=color, width=width)\n",
    "          # print(bound[0])\n",
    "          # image.save(\"temp.jpg\")\n",
    "    return image\n",
    "# draw_boxes(im, bounds)\n",
    "def concatenate_list_data(list):\n",
    "    result= ''\n",
    "    for element in list:\n",
    "        result = result +str(element)\n",
    "    return result\n",
    "\n",
    "\n",
    "for s in filenames:\n",
    "    # s = \"Invoice0.jpg\"\n",
    "    filen = s.split(\".\")[0]\n",
    "    print(filen)\n",
    "    im = PIL.Image.open(s).convert('RGB')\n",
    "    # Doing OCR. Get bounding boxes.\n",
    "    bounds = reader.readtext(s)\n",
    "    im = PIL.Image.open(s).convert('RGB')\n",
    "    df = pd.DataFrame()\n",
    "    CoordinatesValue = []\n",
    "    for i in bounds:\n",
    "        Coordinates =[]\n",
    "        CoordinatesValue=[]\n",
    "        temp_df = pd.DataFrame()\n",
    "        Coordinates.append(concatenate_list_data(i[0]).replace(\"][\",\",\").replace(\"[\",\"\").replace(\"]\",\"\").replace(\" \",\"\"))\n",
    "#         print(i[1])\n",
    "        CoordinatesValue.append(i[1])\n",
    "        temp_df = DataFrame(zip(Coordinates,CoordinatesValue),columns = ['Coordinates', 'Value'])\n",
    "#         print(temp_df)\n",
    "        df = df.append(temp_df)\n",
    "    # print(item[0])\n",
    "    combine_lambda = lambda x: '{},{}'.format(x.Coordinates, x.Value)\n",
    "    df['Result'] = df.apply(combine_lambda, axis = 1)\n",
    "    dfnew= df['Result']\n",
    "    dfnew = dfnew[0].str.split(',', expand=True)\n",
    "    dfnew.insert(0,'name_of_column','')\n",
    "    dfnew['name_of_column'] = 1\n",
    "#     dfnew.to_csv(str(filen)+\".tsv\",  sep = ',',index=False ,header=False )\n",
    "    dfnew.to_csv(str(filen)+\".tsv\",sep = ',',index=False,header=False, quotechar='',escapechar='\\\\',quoting=csv.QUOTE_NONE, )\n",
    "\n",
    "### copy file from source folder to destination folder ###\n",
    "for f in filenames:\n",
    "    shutil.copy(f, 'test_img/')\n",
    "    \n",
    "filetsv = glob.glob(\"/Volumes/Extreme SSD/MLWork/DocAI/TestImage/*.tsv\")\n",
    "for f in filetsv:\n",
    "    shutil.copy(f, 'test_boxes_and_transcripts/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b868b0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/Extreme SSD/MLWork/DocAI/PICK-pytorch\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'allennlp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-c372a0f45ea4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mallennlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_readers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspan_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbio_tags_to_spans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mparse_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConfigParser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpick\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpick_arch_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'allennlp'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "# path = '/Users/neerajyadav/Documents/pycv/PICK-pytorch/'\n",
    "path = '/Volumes/Extreme SSD/MLWork/DocAI/PICK-pytorch'\n",
    "os.chdir(path)\n",
    "import argparse\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from allennlp.data.dataset_readers.dataset_utils.span_utils import bio_tags_to_spans\n",
    "from parse_config import ConfigParser\n",
    "import model.pick as pick_arch_module\n",
    "from data_utils.pick_dataset import PICKDataset\n",
    "from data_utils.pick_dataset import BatchCollateFn\n",
    "from utils.util import iob_index_to_str, text_index_to_str\n",
    "import converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8862a7e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
